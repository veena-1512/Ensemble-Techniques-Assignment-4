{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a487c18-f416-4eaa-93de-c63c1918aea9",
   "metadata": {},
   "source": [
    "Q1 Design a pipeline that includes the following steps\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5f0bff-20de-4643-8c3a-2ea24bd41089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target names: ['setosa' 'versicolor' 'virginica']\n",
      "Number of samples: 150\n",
      "Number of features: 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# The data is stored in the 'data' attribute\n",
    "X = iris.data\n",
    "\n",
    "# The target values are stored in the 'target' attribute\n",
    "y = iris.target\n",
    "\n",
    "# If you want to get the feature names and target names, you can use:\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(\"Feature names:\", feature_names)\n",
    "print(\"Target names:\", target_names)\n",
    "print(\"Number of samples:\", X.shape[0])\n",
    "print(\"Number of features:\", X.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c39bd276-8723-48ca-8bab-72dbcd378519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data with missing values:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                NaN               NaN                NaN               0.2\n",
      "2                4.7               3.2                NaN               0.2\n",
      "3                4.6               3.1                NaN               NaN\n",
      "4                5.0               3.6                1.4               0.2\n",
      "5                5.4               NaN                1.7               0.4\n",
      "6                4.6               3.4                NaN               0.3\n",
      "7                5.0               NaN                1.5               NaN\n",
      "8                NaN               2.9                1.4               0.2\n",
      "9                4.9               NaN                1.5               0.1\n",
      "\n",
      "Imputed data:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           5.100000          3.500000           1.400000          0.200000\n",
      "1           5.864348          3.052941           3.679646          0.200000\n",
      "2           4.700000          3.200000           3.679646          0.200000\n",
      "3           4.600000          3.100000           3.679646          1.207627\n",
      "4           5.000000          3.600000           1.400000          0.200000\n",
      "5           5.400000          3.052941           1.700000          0.400000\n",
      "6           4.600000          3.400000           3.679646          0.300000\n",
      "7           5.000000          3.052941           1.500000          1.207627\n",
      "8           5.864348          2.900000           1.400000          0.200000\n",
      "9           4.900000          3.052941           1.500000          0.100000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "\n",
    "# Introduce some missing values (replace 20% of the values with NaN)\n",
    "np.random.seed(42)\n",
    "missing_mask = np.random.rand(*X.shape) < 0.2\n",
    "X_with_missing = X.copy()\n",
    "X_with_missing[missing_mask] = np.nan\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame(X_with_missing, columns=iris.feature_names)\n",
    "\n",
    "# Impute missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(df)\n",
    "\n",
    "# Convert the result back to a NumPy array\n",
    "X_imputed = np.array(X_imputed)\n",
    "\n",
    "# Print the original data with missing values\n",
    "print(\"Original data with missing values:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Print the imputed data\n",
    "print(\"\\nImputed data:\")\n",
    "print(pd.DataFrame(X_imputed, columns=iris.feature_names).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c660069-5b7c-4ba9-af61-4b01886c77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the data and then transform the data\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8bc9ed-e2a9-4e2b-a811-7970a9d7466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "One hot-Encoding:- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4980a32f-9e41-4161-bac8-2cff97afc38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_Blue  Color_Green  Color_Red\n",
      "0           0            0          1\n",
      "1           1            0          0\n",
      "2           0            1          0\n",
      "3           0            0          1\n",
      "4           1            0          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Color': ['Red', 'Blue', 'Green', 'Red', 'Blue']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform one-hot encoding using pandas\n",
    "df_encoded = pd.get_dummies(df, columns=['Color'])\n",
    "\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be2943e-330d-43dd-a059-76c2b9e1932b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8a076-5b74-494e-a9f2-760c7435f0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "20aecbab-0353-4f70-a755-a7ca27992ee6",
   "metadata": {},
   "source": [
    "Q2. Build a pipeline that includes a random forest classifier and a loistic regression classifier, and then \n",
    "use a voting classifier to comine their preicions. Train the pipeline on the iris dataset and evaluate its \n",
    "accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c12f49-7d9f-476c-b181-eb16b0b6cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Create a Voting Classifier that combines predictions from Random Forest and Logistic Regression\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('rf', rf_classifier),\n",
    "    ('lr', lr_classifier)\n",
    "], voting='hard')\n",
    "\n",
    "# Create a pipeline that includes the Voting Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('voting', voting_classifier)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6deeaa-d9cc-4bdf-badc-d6c3003c3da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71519c9-88ba-42ff-9adc-0057391b5290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1186d-d483-4ccf-a04e-390b30850433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d89eb-5b5e-42ad-a49f-cf66bf0497e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
